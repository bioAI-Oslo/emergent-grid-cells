{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b658befc-513e-4661-b5bf-6112e7065908",
   "metadata": {},
   "source": [
    "Importing relevant packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480af7b-9569-48db-960a-b5c8cc94d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0704a08-5f45-41a2-be2f-c2c2f2d761e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('bioAI.mplstyle')\n",
    "\n",
    "'''\n",
    "CUSTOM PACKAGES\n",
    "'''\n",
    "# avoid adding multiple relave paths to sys.path\n",
    "sys.path.append(\"../src\") if \"../src\" not in sys.path else None\n",
    "\n",
    "from Models import SorscherRNN\n",
    "from Experiment import Experiment\n",
    "from datahandling import Dataset, MESampler\n",
    "from plotting_functions import *\n",
    "from synthetic_grid_cells import *\n",
    "from methods import *\n",
    "from stats import *\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5968f-3392-49e4-a23e-0630f4fc1b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_path = Path(\"/storA/GridCells/\")\n",
    "base_path = \"/mnt/WD12TB-HDD\"\n",
    "experiment = Experiment(name=\"gg-3ME\", base_path=base_path)\n",
    "experiment.setup()\n",
    "boxsize = experiment.environments[0].boxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de048cf4-3802-4d0b-8432-df9ad57a3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_indices = np.load(f\"{experiment.paths['experiment']}/module_indices_uninteresting.npz\")\n",
    "print(module_indices.files)\n",
    "clusters = [module_indices[f] for f in module_indices.files]\n",
    "\n",
    "module_indices = np.load(f\"{experiment.paths['experiment']}/module_indices_new.npz\")\n",
    "print(module_indices.files)\n",
    "module_indices = module_indices['C0_from_env_2']\n",
    "ncells = len(module_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratemaps = utils.load_ratemaps(experiment)\n",
    "mean_fire = np.nanmean(ratemaps[1][clusters[0]],axis=(1,2))\n",
    "baddies = np.argsort(mean_fire)[::-1][:8]\n",
    "ratemaps = [] # free up memory\n",
    "clusters[0] = np.delete(clusters[0],baddies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "    print(len(cluster), len(set(cluster).intersection(set(module_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90b2c4f-46a5-4a74-844a-d3276b53d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(experiment, random_model=False):\n",
    "    # load weights\n",
    "    checkpoint_filenames = filenames(experiment.paths['checkpoints'])\n",
    "    # load model latest (wrt. #epochs trained)\n",
    "    print(f\"Loading model at epoch = {checkpoint_filenames[-1]}\", experiment.paths['checkpoints'] / checkpoint_filenames[-1])\n",
    "    checkpoint = torch.load(experiment.paths['checkpoints'] / checkpoint_filenames[-1])\n",
    "    # instantiate trained model this time\n",
    "    model = SorscherRNN(experiment.pc_ensembles, Ng=experiment.params['Ng'], Np=experiment.params['Np'])\n",
    "    if not random_model:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model\n",
    "\n",
    "model = load_model(experiment)\n",
    "random_model = load_model(experiment, random_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0fa60-b290-4e16-b9ae-41386b4c6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach experiment specifics\n",
    "params = experiment.params\n",
    "environments = experiment.environments\n",
    "agents = experiment.agents\n",
    "pc_ensembles = experiment.pc_ensembles\n",
    "paths = experiment.paths\n",
    "\n",
    "num_workers = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"{device=}\")\n",
    "\n",
    "# Initialise data loading\n",
    "num_samples = params['nsteps'] * params['batch_size'] # * params['nepochs']\n",
    "dataset = Dataset(agents = agents, pc_ensembles = pc_ensembles, num_samples = num_samples, seq_len=20)#, **params)\n",
    "datasampler = eval(params['sampler'])(num_environments = len(environments), num_samples = num_samples, \\\n",
    "                                      num_epochs = params['nepochs'])\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=params['batch_size'], sampler = datasampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6786796-b417-46c6-89d0-6730e43f2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_inference(model, inputs, labels, positions, indices, trajectory_slice=None):\n",
    "    trajectory_slice = slice(0,positions.shape[1]) if trajectory_slice is None else trajectory_slice\n",
    "    position_slice = slice(trajectory_slice.start,trajectory_slice.stop+1)\n",
    "    indices = np.array(indices)\n",
    "    log_predictions = model(inputs, log_softmax=True)\n",
    "    #loss = self.loss_fn(log_predictions, labels, weight_decay)\n",
    "    #labels = labels.to(self.device, dtype=self.dtype)\n",
    "    positions = positions.to(model.device, dtype=model.dtype)\n",
    "    pred_error = model.position_error(log_predictions[:,trajectory_slice], \n",
    "                                      positions[:,position_slice], indices, model.place_cell_ensembles)\n",
    "    return pred_error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3a65d-4b3e-4061-a3e4-893eca69dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model, dataloader, module_indices, clusters, nsteps=40, trajectory_slice=slice(19,20)):\n",
    "    pe_true = []\n",
    "    pe_cluster0 = []\n",
    "    pe_cluster1 = []\n",
    "    pe_cluster2 = []\n",
    "    pe_random_model = []\n",
    "\n",
    "    # bag/hat to keep continuous pruning idxs in\n",
    "    cluster0 = np.array([])\n",
    "    cluster1 = np.array([])\n",
    "    cluster2 = np.array([])\n",
    "\n",
    "    i = 0\n",
    "    for inputs, labels, positions, indices in dataloader:\n",
    "        if i == nsteps:\n",
    "            break\n",
    "\n",
    "        # get number of cells to prune\n",
    "        if (len(module_indices) % nsteps) > i:\n",
    "            ncells2prune = int(len(module_indices)  / nsteps) + 1\n",
    "        else:\n",
    "            ncells2prune = int(len(module_indices)  / nsteps)\n",
    "\n",
    "        # true\n",
    "        model.prune_mask = []\n",
    "        pe_true.append(pred_inference(model, inputs, labels, positions, indices, trajectory_slice))\n",
    "\n",
    "        # cluster 0\n",
    "        remaining = list(set(clusters[0]) - set(cluster0))\n",
    "        tmp = np.random.choice(remaining, size=ncells2prune if len(remaining) > ncells2prune else len(remaining), replace=False)\n",
    "        cluster0 = np.append(cluster0, tmp).astype(int)\n",
    "        model.prune_mask = cluster0\n",
    "        pe_cluster0.append(pred_inference(model, inputs, labels, positions, indices, trajectory_slice))\n",
    "\n",
    "        # cluster 1\n",
    "        remaining = list(set(clusters[1]) - set(cluster1))\n",
    "        tmp = np.random.choice(remaining, size=ncells2prune if len(remaining) > ncells2prune else len(remaining), replace=False)\n",
    "        cluster1 = np.append(cluster1, tmp).astype(int)\n",
    "        model.prune_mask = cluster1\n",
    "        pe_cluster1.append(pred_inference(model, inputs, labels, positions, indices, trajectory_slice))\n",
    "\n",
    "        # cluster 2\n",
    "        remaining = list(set(clusters[2]) - set(cluster2))\n",
    "        tmp = np.random.choice(remaining, size=ncells2prune if len(remaining) > ncells2prune else len(remaining), replace=False)\n",
    "        cluster2 = np.append(cluster2, tmp).astype(int)\n",
    "        model.prune_mask = cluster2\n",
    "        pe_cluster2.append(pred_inference(model, inputs, labels, positions, indices, trajectory_slice))\n",
    "\n",
    "        # random model\n",
    "        pe_random_model.append(pred_inference(random_model, inputs, labels, positions, indices, trajectory_slice))\n",
    "        \n",
    "        i+=1\n",
    "            \n",
    "    return pe_true, pe_cluster0, pe_cluster1, pe_cluster2, pe_random_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029c5dd-cbc6-47fe-9207-a9730cd1926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_stats(nstats, *args, **kwargs):\n",
    "    stats = []\n",
    "    for j in tqdm.trange(nstats):\n",
    "        stats.append(np.array(prune_model(*args, **kwargs)))\n",
    "    return np.array(stats) # shape: (nstats x 6 x nsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef48ccd-3ae5-42b1-b315-860b53951e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 60\n",
    "nstats = 30\n",
    "load_stats = False\n",
    "\n",
    "if load_stats:\n",
    "    with open(experiment.paths['experiment'] / \"pruning_errors_uninteresting_clusters.pkl\", \"rb\") as f:\n",
    "        pruning_errors = pickle.load(f)\n",
    "else:\n",
    "    pruning_errors = prune_stats(nstats, model, dataloader, module_indices, clusters, nsteps=nsteps)\n",
    "    # save pruning errors statistics - since it takes so long to compute it can be loaded instead\n",
    "    with open(experiment.paths['experiment'] / \"pruning_errors_uninteresting_clusters.pkl\", \"wb\") as f:\n",
    "        pickle.dump(pruning_errors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8d486-d1d7-4e5a-a0fd-3088229d5589",
   "metadata": {},
   "outputs": [],
   "source": [
    "panesize = set_size(width=345, mode='tall')\n",
    "panesize\n",
    "\n",
    "figsize=(panesize[0],panesize[1]*2/6)\n",
    "figsize=np.array(figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1824237-a0cd-4cc0-af0a-8940b088c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "x_ticks = np.linspace(0, ncells, nsteps)\n",
    "labels = ['Full Model', 'Cluster1', 'Cluster2', 'Cluster3', 'Full Untrained Model']\n",
    "ls = ['-']*len(labels)\n",
    "ls[0] = '-.'\n",
    "ls[-1] = '-.'\n",
    "\n",
    "mean_error = np.mean(pruning_errors,axis=0)\n",
    "std_error = np.std(pruning_errors,axis=0)\n",
    "median_error = np.median(pruning_errors,axis=0)\n",
    "mad_error = mad(pruning_errors,axis=0)\n",
    "for i in range(len(labels)): # set order to change color according to color-cycler\n",
    "    ax.plot(x_ticks, mean_error[i], label=labels[i])#np.mean(pruning_i,axis=0))\n",
    "    ax.fill_between(x_ticks, mean_error[i] + std_error[i], mean_error[i] - std_error[i], alpha=0.1)\n",
    "    #ax.plot(x_ticks, median_error[i], label=labels[i], ls=ls[i])#np.mean(pruning_i,axis=0))\n",
    "    #ax.fill_between(x_ticks, median_error[i] + mad_error[i], median_error[i] - mad_error[i], alpha=0.1)\n",
    "\n",
    "ax.scatter(x_ticks[None]*np.ones((30,1)), pruning_errors[:,1], s=5, alpha=0.5, c=ax.lines[-1].get_color())\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('#Pruned Cells')\n",
    "ax.set_ylabel('Decoding Error')\n",
    "\n",
    "ax.axvline(20, ls=':')\n",
    "ax.axvline(50, ls=':')\n",
    "ax.axvline(200, ls=':')\n",
    "\n",
    "#fig.savefig(\"/home/vemundss/Desktop/prune\")\n",
    "#fig.savefig(experiment.paths['experiment'] / f'plots/pruning')\n",
    "fig.savefig(experiment.paths['experiment'] / f'plots/pruning_uninteresting_clusters')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b840bce-001b-4359-a28f-a988f89ce3b6",
   "metadata": {},
   "source": [
    "### Investigate pruning distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a02893-9026-40a9-b366-05d7b487b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_type_id = 1\n",
    "\n",
    "for i in range(pruning_errors.shape[-1]):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.hist(pruning_errors[:,prune_type_id,i])\n",
    "    m = np.mean(pruning_errors,axis=0)[prune_type_id,i]\n",
    "    s = np.std(pruning_errors,axis=0)[prune_type_id,i]\n",
    "    med = np.median(pruning_errors,axis=0)[prune_type_id,i]\n",
    "    ma = mad(pruning_errors,axis=0)[prune_type_id,i]\n",
    "    ax.axvline(m, color='green')\n",
    "    ax.axvline(m + s, color='red')\n",
    "    ax.axvline(m - s, color='red')\n",
    "    \n",
    "    ax.axvline(med, ls=':', color='green')\n",
    "    ax.axvline(med + ma, ls=':', color='red')\n",
    "    ax.axvline(med - ma, ls=':', color='red')\n",
    "    #ax.set_title(np.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ad301-3def-47d2-91b5-8fffe87afa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(pruning_errors,axis=0)[1], np.max(pruning_errors,axis=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdd721-e812-48d8-9611-006849b0e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ticks = np.linspace(0, ncells, len(pe_true))\n",
    "plt.plot(x_ticks, pe_true, label='Full Model')\n",
    "plt.plot(x_ticks, pe_random, label='Random Pruning')\n",
    "plt.plot(x_ticks, pe_gcs, label='High GCS Pruning')\n",
    "plt.plot(x_ticks, pe_random_torus, label='Random Torus Pruning')\n",
    "#plt.plot(x_ticks, pe_sorted_torus, label='Sorted Torus Pruning')\n",
    "plt.plot(x_ticks, pe_random_inverse_torus, label='Random Inverse Torus Pruning')\n",
    "plt.legend()\n",
    "plt.xlabel('#Pruned Cells')\n",
    "plt.ylabel('Decoding Error')\n",
    "\n",
    "plt.savefig(\"/home/vemundss/Desktop/prune\")\n",
    "plt.savefig(experiment.paths['experiment'] / f'plots/pruning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc129b6b-11ca-46f6-be0a-62e1226a7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT\n",
    "# -- DONE -- prune with high GCS\n",
    "# -- DONE -- prune toroid cells sorted on phase - physics phase transtition?\n",
    "# legg til error shadings på grafene.\n",
    "# include adverserial attack?\n",
    "# -- DONE -- prune inverse of toroid cells. path integration remain? ratemaps still grids? toroid still there?\n",
    "# select phases based on e.g. right side of box.\n",
    "\n",
    "# Include random initialised network without pruning to show baseline decoding error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

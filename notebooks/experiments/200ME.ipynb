{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be522a85-71a1-4918-a711-f493aefb26ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996cfee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f109164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computational packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "# General packages\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# custom packages\n",
    "import ratsimulator\n",
    "from ratsimulator.Environment import Rectangle\n",
    "import spatial_maps as sm # CINPLA spatial maps\n",
    "\n",
    "# avoid adding multiple relave paths to sys.path\n",
    "sys.path.append(\"../../src\") if \"../../src\" not in sys.path else None \n",
    "from PlaceCells import PlaceCells\n",
    "from Models import SorscherRNN\n",
    "from Experiment import Experiment\n",
    "from methods import *\n",
    "from datahandling import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb2b7a-33d6-499f-b899-7f249416b36d",
   "metadata": {},
   "source": [
    "### Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ff00f3-81cd-4031-8e86-28d9955f6572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment <200ME> already EXISTS. Loading experiment settings!\n",
      "Loading experiment details\n",
      "This experiment has ALREADY been setup - SKIPPING.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = Experiment(name = '200ME')\n",
    "if experiment.is_new_experiment:\n",
    "    experiment.params['nepochs'] = 12000\n",
    "    for i in range(1,200):\n",
    "        environments, agents, pc_ensembles = experiment.get_default_ecology(seed = i)\n",
    "        experiment.environments += environments\n",
    "        experiment.agents += agents\n",
    "        experiment.pc_ensembles += pc_ensembles\n",
    "        \n",
    "# experiment.params['nepochs'] = 16000\n",
    "# with open(experiment.paths['experiment'] / \"params.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(experiment.params, f)\n",
    "\n",
    "experiment.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "530b5b7b-f788-45d5-a318-61e2cab433a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "# detach experiment specifics\n",
    "params = experiment.params\n",
    "environments = experiment.environments\n",
    "agents = experiment.agents\n",
    "pc_ensembles = experiment.pc_ensembles\n",
    "paths = experiment.paths\n",
    "\n",
    "num_workers = 30\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"{device=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626330b4-f133-4ac8-bc0f-2c75b3ae70dd",
   "metadata": {},
   "source": [
    "### Initialise objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cff29f0-2cb5-4eb8-9ece-72a72fb91141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = SorscherRNN(\n",
      "  (init_position_encoder): Linear(in_features=512, out_features=4096, bias=False)\n",
      "  (RNN): RNN(2, 4096, bias=False, batch_first=True)\n",
      "  (decoder): Linear(in_features=4096, out_features=512, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialise data loading\n",
    "num_samples = params['nsteps'] * params['batch_size'] # * params['nepochs']\n",
    "dataset = Dataset(agents = agents, pc_ensembles = pc_ensembles, num_samples = num_samples, **params)\n",
    "datasampler = eval(params['sampler'])(num_environments = len(environments), num_samples = num_samples, \\\n",
    "                                      num_epochs = params['nepochs'])\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=params['batch_size'], sampler = datasampler, num_workers=num_workers)\n",
    "\n",
    "# Initialise model\n",
    "model = SorscherRNN(pc_ensembles, Ng=params['Ng'], Np=params['Np'])\n",
    "model.to(device)\n",
    "print(f\"{model = }\")\n",
    "\n",
    "# Initialise optimizer (use custom weight decay, rather than torch optim decay)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], betas=(0.9, 0.999), \\\n",
    "                             eps=1e-08, weight_decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ee8580-f195-4621-a75c-6ad55e76a58d",
   "metadata": {},
   "source": [
    "### Train/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad08929-98de-4862-adcb-460f5fb06c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model at epoch = 11999\n",
      "Loaded weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch=13444/16000, loss=6.2357415771484375, decoding_error(pred/true)=0.7424153077602387/0.0412656132504344:  36%|███▌      | 1445/4000 [5:27:00<9:41:51, 13.66s/it]   "
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "training_metrics = {}\n",
    "checkpoint_filenames = filenames(paths['checkpoints'])\n",
    "\n",
    "if checkpoint_filenames:\n",
    "    # load model latest (wrt. #epochs trained)\n",
    "    print(f\"Loading model at epoch = {checkpoint_filenames[-1]}\")\n",
    "    checkpoint = torch.load(paths['checkpoints'] / checkpoint_filenames[-1])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    loss_history = checkpoint['loss_history']\n",
    "    training_metrics = checkpoint['training_metrics']\n",
    "    print(\"Loaded weights\")\n",
    "    \n",
    "    if isinstance(datasampler, CLSampler):\n",
    "        datasampler.epoch_counter = len(loss_history)\n",
    "    \n",
    "# whether to train\n",
    "if train:=True:\n",
    "    loss_history, training_metrics = model.train(trainloader = dataloader, optimizer = optimizer, weight_decay=params['weight_decay'], \\\n",
    "                               nepochs=params['nepochs'], checkpoint_path = paths['checkpoints'], \\\n",
    "                               loss_history = loss_history, training_metrics = training_metrics)\n",
    "    # (re)load checkpoint strs and latest checkpoint\n",
    "    checkpoint_filenames = filenames(paths['checkpoints'])\n",
    "    checkpoint = torch.load(paths['checkpoints'] / checkpoint_filenames[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a35a08-d3f8-40a0-9be7-ddc9b010f8c4",
   "metadata": {},
   "source": [
    "## **Analyse Model**\n",
    "### Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4dd377-770d-4347-b54b-703b24a03183",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=len(training_metrics) + 1,figsize=(15,4))\n",
    "ax[0].plot(loss_history)\n",
    "ax[0].plot(training_metrics['entropy'], label='optima')\n",
    "ax[0].set_title('Total-loss history')\n",
    "ax[0].legend()\n",
    "\n",
    "for i,(key,value) in enumerate(training_metrics.items()):\n",
    "    ax[i+1].plot(value)\n",
    "    ax[i+1].set_title(key)\n",
    "    if key == 'KL':\n",
    "        ax[i+1].axhline(0,ls=\":\")\n",
    "    if key == 'pred_error':\n",
    "        ax[i+1].axhline(np.mean(training_metrics['true_error']),ls=\":\")\n",
    "    if key == 'CE':\n",
    "        ax[i+1].plot(training_metrics['entropy'], label='optima')\n",
    "        ax[i+1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# maximum labelled distribution entropy (uniform labelled distribution)\n",
    "n = 512\n",
    "px = np.ones(n) / n # uniform\n",
    "entropy = lambda x: -np.sum(x * np.log(x))\n",
    "print(f\"Maximum Entropy possible: {entropy(px)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d7c36-c6fe-40ff-9747-fb9103e84fbe",
   "metadata": {},
   "source": [
    "### Create ratemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a51a812-6e9c-42c3-890c-27c7d28339e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratemap_trajectories(dataset, environment_idx, num_trajectories=1500):\n",
    "    \"\"\"Generate trajectories to compute ratemaps with (scipy.stats.binned_statistics_2d)\"\"\"\n",
    "    batch_velocities, batch_init_pc_positions, batch_positions = [], [], []\n",
    "    for _ in range(num_trajectories):\n",
    "        (velocities, init_pc_positions), _, positions, _ = dataset[environment_idx]\n",
    "        batch_velocities.append(velocities)\n",
    "        batch_init_pc_positions.append(init_pc_positions)\n",
    "        batch_positions.append(positions)\n",
    "    batch_inputs = [torch.stack(batch_velocities), torch.stack(batch_init_pc_positions)]\n",
    "    batch_positions = torch.stack(batch_positions).detach().numpy()\n",
    "    x = np.ravel(batch_positions[:,1:,0])\n",
    "    y = np.ravel(batch_positions[:,1:,1])\n",
    "    return batch_inputs, x, y\n",
    "\n",
    "def ratemaps_all_checkpoints(missing_ratemaps_filenames, epoch_ratemaps_env_path, batch_inputs, x, y):\n",
    "    # loop all saved model weights - and create ratemaps\n",
    "    for checkpoint_epoch in tqdm.tqdm(missing_ratemaps_filenames):\n",
    "        epoch_ratemaps_path = epoch_ratemaps_env_path / (checkpoint_epoch + \".pkl\")\n",
    "        \n",
    "        # load model weights, forward (to g) and compute ratemaps\n",
    "        checkpoint = torch.load(paths['checkpoints'] / checkpoint_epoch)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        activities = model.g(batch_inputs).detach().cpu().numpy()\n",
    "        activities = activities.reshape(-1, activities.shape[-1]).T\n",
    "        ratemaps = scipy.stats.binned_statistic_2d(x, y, activities, bins=res)[0]\n",
    "        \n",
    "        # save ratemaps\n",
    "        with open(epoch_ratemaps_path, \"wb\") as f:\n",
    "            pickle.dump(ratemaps,f)\n",
    "\n",
    "# mec_idxs = slice(0, params['Ng'], 1)\n",
    "res = np.array([32, 32])\n",
    "for env_i in range(len(environments)):\n",
    "    print(f\"Creating ratemaps for environment_idx = {env_i+1}/{len(environments)}\")\n",
    "    # create list of missing ratemaps - to be created\n",
    "    ratemaps_filenames = filenames(paths[\"ratemaps\"] / f\"env_{env_i}\")\n",
    "    ratemaps_filenames = [ratemaps_filename.split('.')[0] for ratemaps_filename in ratemaps_filenames]\n",
    "    missing_ratemaps_filenames = list(set(checkpoint_filenames) - set(ratemaps_filenames))\n",
    "    missing_ratemaps_filenames.sort()\n",
    "    if not missing_ratemaps_filenames:\n",
    "        continue\n",
    "    \n",
    "    # generate trajectories to compute ratemaps for\n",
    "    batch_inputs, x, y = ratemap_trajectories(dataset, environment_idx=env_i, num_trajectories=1500)\n",
    "    \n",
    "    epoch_ratemaps_env_path = paths[\"ratemaps\"] / f\"env_{env_i}\"\n",
    "    # loop all saved model weights - and create ratemaps\n",
    "    ratemaps_all_checkpoints(missing_ratemaps_filenames,\\\n",
    "                             epoch_ratemaps_env_path,\\\n",
    "                             batch_inputs\\\n",
    "                             , x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced28740-867e-43e8-9f75-3031d9cd227b",
   "metadata": {},
   "source": [
    "### Create ratemaps for novel environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3a0b8-31db-4ac6-b22e-f8ef97cb40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_environments, novel_agents, novel_pc_ensembles = Experiment.get_default_ecology(seed = 23031994)\n",
    "novel_dataset = Dataset(agents = novel_agents, pc_ensembles = novel_pc_ensembles, num_samples = num_samples, **params)\n",
    "\n",
    "print(f\"Creating ratemaps for novel environment_idx = 1/1\")\n",
    "# create list of missing ratemaps - to be created\n",
    "epoch_ratemaps_env_path = paths[\"ratemaps\"] / \"env_novel\"\n",
    "if not epoch_ratemaps_env_path.exists():\n",
    "    os.makedirs(epoch_ratemaps_env_path)\n",
    "ratemaps_filenames = filenames(paths[\"ratemaps\"] / \"env_novel\")\n",
    "ratemaps_filenames = [ratemaps_filename.split('.')[0] for ratemaps_filename in ratemaps_filenames]\n",
    "missing_ratemaps_filenames = list(set(checkpoint_filenames) - set(ratemaps_filenames))\n",
    "missing_ratemaps_filenames.sort()\n",
    "\n",
    "if missing_ratemaps_filenames:\n",
    "    # generate trajectories to compute ratemaps for\n",
    "    batch_inputs, x, y = ratemap_trajectories(dataset, environment_idx=0, num_trajectories=1500)\n",
    "    # loop all saved model weights - and create ratemaps\n",
    "    ratemaps_all_checkpoints(missing_ratemaps_filenames,\\\n",
    "                             epoch_ratemaps_env_path,\\\n",
    "                             batch_inputs,\\\n",
    "                             x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561c600-522c-4111-8981-149ae1edd6e7",
   "metadata": {},
   "source": [
    "### Load ratemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e21eb-f4f1-44b8-afba-0207d9da97ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_i = 0\n",
    "latest_ratemaps_path = paths[\"ratemaps\"] / f\"env_{env_i}\" / (checkpoint_filenames[-1] + \".pkl\")\n",
    "with open(latest_ratemaps_path, \"rb\") as f:\n",
    "    ratemaps = pickle.load(f)\n",
    "print(\"Loaded ratemaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8b772-08dc-4bc6-9ba7-8e2ec9ff4c17",
   "metadata": {},
   "source": [
    "### Example ratemaps (unsorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53afa647-437b-443f-ad26-b21e672f2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 256*1\n",
    "num_ratemaps = 256\n",
    "fig, ax = multiimshow(ratemaps[start_idx:start_idx+num_ratemaps])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55dccd-4149-4007-beb5-9a489cc13090",
   "metadata": {},
   "source": [
    "### Grid score ratemaps (only last model checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8224284b-0616-4c46-8693-34323490a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ratemaps(ratemaps, environment, env_name):\n",
    "    # if grid scores have already been calculate and saved to disk, load these (FAST!)\n",
    "    score_map_path = paths[\"grid_scores\"] / (checkpoint_filenames[-1] + env_name + \".pkl\")\n",
    "    if os.path.exists(score_map_path):\n",
    "        print(os.path.split(score_map_path)[-1], \"already exists. Loading score map.\")\n",
    "        with open(score_map_path, \"rb\") as f:\n",
    "            score_map = pickle.load(f)\n",
    "        return score_map\n",
    "    \n",
    "    # BANINO (and Sorscher) grid scoring method\n",
    "    from scores import GridScorer\n",
    "    res = np.array([32,32])\n",
    "    starts = [0.2] * 10\n",
    "    ends = np.linspace(0.4, 1.0, num=10)\n",
    "    box_width, box_height = environment.boxsize\n",
    "    coord_range=((environment.origo[0], box_width), (environment.origo[0], box_height))\n",
    "    coords_range=((-box_width/2, box_width/2), (-box_height/2, box_height/2))\n",
    "    mask_parameters = zip(starts, ends.tolist())\n",
    "    scorer = GridScorer(nbins=res[0], coords_range=coords_range, mask_parameters=mask_parameters)\n",
    "\n",
    "    # score ratemaps (Could use NUMBA for faster computations?)\n",
    "    score_map = np.zeros(params['Ng']) # ratemap score lookup table\n",
    "    for i in tqdm.trange(params['Ng']):\n",
    "        # interpolated_ratemap = interpolate_missing_pixels(ratemaps[i], np.isnan(ratemaps[i]))\n",
    "        # score_map[i] = sm.gridness(interpolated_ratemap)\n",
    "        score_60, score_90, max_60_mask, max_90_mask, sac = scorer.get_scores(ratemaps[i])\n",
    "        score_map[i] = score_60\n",
    "\n",
    "    with open(score_map_path, \"wb\") as f:\n",
    "        pickle.dump(score_map,f)\n",
    "    return score_map\n",
    "\n",
    "# create scores for all ratemaps across all environments\n",
    "for env_i in range(len(environments)):\n",
    "    print(f\"Calculating grid score for the ratemaps of environment={env_i+1}/{len(environments)}\")\n",
    "    latest_ratemaps_path_env_i = paths[\"ratemaps\"] / f\"env_{env_i}\" / (checkpoint_filenames[-1] + \".pkl\")\n",
    "    with open(latest_ratemaps_path_env_i, \"rb\") as f:\n",
    "        ratemaps_env_i = pickle.load(f)\n",
    "    score_map = score_ratemaps(ratemaps_env_i, environments[env_i], f\"_env_{env_i}\")\n",
    "# create scores for all ratemaps of novel environment\n",
    "print(f\"Calculating grid score for novel environment\")\n",
    "with open(paths[\"ratemaps\"] / \"env_novel\" / (checkpoint_filenames[-1] + \".pkl\"), \"rb\") as f:\n",
    "    ratemaps_env_novel = pickle.load(f)\n",
    "score_map_env_novel = score_ratemaps(ratemaps_env_novel, novel_environments[0], \"_env_novel\")\n",
    "\n",
    "# choose score map\n",
    "env_i = 0\n",
    "score_map = score_ratemaps(ratemaps, environments[env_i], f\"_env_{env_i}\")\n",
    "\n",
    "# sort scores and ratemaps\n",
    "sort_idxs = np.argsort(score_map)[::-1]\n",
    "sorted_scores = score_map[sort_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730d0a1-1840-4d05-a317-edbaa306196c",
   "metadata": {},
   "source": [
    "### Example ratemaps (sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ac0f6-29cc-4b3a-a56f-3ce230f16685",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "num_ratemaps = 2**6\n",
    "fig, axs = multiimshow(ratemaps[sort_idxs][start_idx:start_idx+num_ratemaps], titles=sort_idxs[start_idx:start_idx+num_ratemaps])\n",
    "fig.suptitle(f\"gc_score = {sorted_scores[start_idx]} -- {sorted_scores[start_idx+num_ratemaps]}\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e51f5-a124-4dd4-ad9d-c54a553845e5",
   "metadata": {},
   "source": [
    "### Create grid cell ratemap dynamics (grid cell emergence video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73e6bb-dc03-419f-9aa5-56c51c5a4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamics import RatemapDynamics\n",
    "for env_i in range(len(environments)):\n",
    "    print(f\"Creating grid dynamics for the ratemaps of environment={env_i+1}/{len(environments)}\")\n",
    "    \n",
    "    # concatenating ratemaps\n",
    "    ratemap_dynamics = []\n",
    "    print(\"Loading ratemaps\")\n",
    "    for checkpoint_epoch in tqdm.tqdm(checkpoint_filenames):\n",
    "        with open(paths[\"ratemaps\"] / f\"env_{env_i}\" / (checkpoint_epoch + \".pkl\"), \"rb\") as f:\n",
    "            # load and sort ratemaps wrt. grid score\n",
    "            ratemap_dynamics.append(pickle.load(f)[sort_idxs])\n",
    "    ratemap_dynamics = np.stack(ratemap_dynamics, axis=0)\n",
    "    \n",
    "    # creating videos from ratemaps\n",
    "    num_gc_in_video = 64\n",
    "    num_videos = params['Ng'] // num_gc_in_video\n",
    "    print(\"Creating videos\")\n",
    "    for gcs_i in tqdm.trange(0, num_videos):\n",
    "        idxs = slice(gcs_i * num_gc_in_video, (gcs_i + 1) * num_gc_in_video)\n",
    "        if os.path.exists(paths[\"dynamics\"] / f\"env_{env_i}\" / f'{idxs.start}-{idxs.stop - 1}.mp4'):\n",
    "            continue\n",
    "        ratemap_video = RatemapDynamics(ratemap_dynamics[:,idxs], sorted_scores[idxs], sort_idxs[idxs], epochs = checkpoint_filenames)\n",
    "        ratemap_video.animation.save(paths[\"dynamics\"] / f\"env_{env_i}\" / f'{idxs.start}-{idxs.stop - 1}.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a7f22-e27d-4971-8115-1132ebf9f568",
   "metadata": {},
   "source": [
    "### Predicted place Cells (with(out) SOFTMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909fbd0-c6e8-47e6-aadd-46c3607fe07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward_with_softmax = lambda x: torch.exp(model(x, log_softmax=True))\n",
    "ratemaps = compute_ratemaps(model=model, dataset=dataset, num_trajectories=1250, res=res, idxs=idxs)[0]\n",
    "fig, ax = multiimshow(ratemaps)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd1d49-da3f-4566-bdaa-d4e1b86d8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prune_mask = list(range(int(4096/2),4096)) # set prune mask\n",
    "model.prune_mask = [] # reset prune mask\n",
    "model.prune_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860630b-994e-4cd1-be6a-60d62aaaed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=slice(0, 16**2, 1)\n",
    "res=np.array([32, 32])\n",
    "ratemaps = compute_ratemaps(model=model.g, dataset=dataset, num_trajectories=1250, res=res, idxs=idxs)[0]\n",
    "fig, ax = multiimshow(ratemaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40c4a6-f727-4fd7-928c-a583c08ea080",
   "metadata": {},
   "source": [
    "### Decoding labels and predictions to cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f3b6b-92cc-412c-b038-11bb8e02cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_idx = 0\n",
    "[[vel, init_pos], labels, positions, index] = dataset[environment_idx]\n",
    "true_cartesian_pos = positions\n",
    "true_decoded_pos = pc_ensembles[environment_idx].to_euclid(torch.cat([init_pos[None], labels]))\n",
    "pc_preds = model([vel, init_pos]).detach().cpu()[0]\n",
    "predicted_decoded_pos = pc_ensembles[environment_idx].to_euclid(torch.cat([init_pos[None], pc_preds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888cd951-d0ca-47f7-93df-a48bd4cd6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(*true_cartesian_pos.T, label='true_cartesian_pos')\n",
    "ax.plot(*true_decoded_pos.T, label='true_decoded_pos')\n",
    "ax.plot(*predicted_decoded_pos.T, label='predicted_decoded_pos', ls=':')\n",
    "environments[environment_idx].plot_board(ax)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f961bd5c-05ce-4ec0-9e89-9845243e38cb",
   "metadata": {},
   "source": [
    "### Plot all place cell centers and some with tuning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0284b-16f7-401d-af6a-1e042e2b4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x,y = pc_ensembles[environment_idx].pcs.T\n",
    "\n",
    "ax.plot(x, y, \"+\")\n",
    "# add standard deviation circles to locations\n",
    "for i in range(5):\n",
    "    ax.plot(x[i], y[i], \"r+\")\n",
    "    a_circle = plt.Circle((x[i], y[i]), pc_ensembles[0].pc_width, fill=False, color=(1, 0, 0, 0.5))\n",
    "    ax.add_artist(a_circle)\n",
    "\n",
    "plt.title(\"Spatial plot of place cell locations\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba8623-47eb-424d-95b9-6d80d79de68c",
   "metadata": {},
   "source": [
    "### Calculate grid scores using different implementations of the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20675fc-dc2e-4ff7-87c1-5bff46d83dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom grid score\n",
    "print(\"CUSTOM:\", grid_score(ratemaps[1])) \n",
    "\n",
    "# CINPLA grid score\n",
    "import spatial_maps as sm\n",
    "print(\"CINPLA:\", sm.gridness(ratemaps[1])) \n",
    "\n",
    "# BANINO (and Sorscher) grid scoring\n",
    "from scores import GridScorer\n",
    "\"\"\"\n",
    "One difference from custom and CINPLA grid scores: \n",
    "1. Uses average difference between phase60 and phase30 correlations\n",
    "\"\"\"\n",
    "starts = [0.2] * 10\n",
    "ends = np.linspace(0.4, 1.0, num=10)\n",
    "coord_range=((0, environment.boxsize[0]), (0, environment.boxsize[1]))\n",
    "box_width, box_height = 2.2, 2.2\n",
    "coords_range=((-box_width/2, box_width/2), (-box_height/2, box_height/2))\n",
    "mask_parameters = zip(starts, ends.tolist())\n",
    "scorer = GridScorer(nbins=res[0], coords_range=coords_range, mask_parameters=mask_parameters)\n",
    "\n",
    "#score_60, score_90, max_60_mask, max_90_mask, sac, max_60_ind = zip(\n",
    "#      *[scorer.get_scores(rm.reshape(res, res)) for rm in tqdm(rate_map_lores)])\n",
    "score_60, score_90, max_60_mask, max_90_mask, sac = scorer.get_scores(ratemaps[1])\n",
    "print(\"BANINO/SORSCHER:\", score_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80105ea-8683-4c30-a027-e0c958c4bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose grid scoring function to use, e.g: grid_score, sm.gridness or scorer.get_scores\n",
    "# for scorer.get_scores use: < (lambda rm: scorer.get_scores(rm)[0])(rate_map) >\n",
    "grid_scoring_fn = lambda rate_map: sm.gridness(rate_map)\n",
    "\n",
    "#map(grid_scoring_fn, *ratemaps)\n",
    "grid_scoring_fn(ratemaps[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3cbc7d-5feb-4d5e-acdb-99c88f14b1fe",
   "metadata": {},
   "source": [
    "### Small analysis / checks / tests etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211373b1-2a56-49ea-b6c3-4ab5de3a088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wr = model.recurrence.weight.detach().cpu().numpy()\n",
    "Wr = model.RNN.weight_hh_l0.detach().cpu().numpy()\n",
    "stats = lambda W : print(f\"{np.min(W)=}, {np.max(W)=}, {np.min(abs(W))=}, {np.mean(W)=}, {np.std(W)=}, {np.sum(W**2)=}\")\n",
    "stats(Wr)\n",
    "plt.imshow(Wr[:25,:25])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ae245-f59f-4ee6-b3c3-6f5b8ab29a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wp = model.init_position_encoder.weight.detach().cpu().numpy()\n",
    "stats(Wp)\n",
    "plt.imshow(Wp)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd4981-2870-4fca-a590-ae8b55792942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
